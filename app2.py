import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from PIL import Image
import fitz  # pymupdf
import datetime
import io
import openai
import base64

# ==========================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
# Gemini API Key (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
GEMINI_API_KEY_DEFAULT = "" 
# Gemini Model Name
GEMINI_MODEL_NAME = "gemini-flash-latest"
# OpenAI Model Name
OPENAI_MODEL_NAME = "gpt-4o-mini"
# ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆ
USD_JPY_RATE = 155.0
# OpenAI Cost
COST_INPUT_PER_1M = 0.15
COST_OUTPUT_PER_1M = 0.60

# ==========================================
# åˆæœŸåŒ–ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==========================================
if "history" not in st.session_state:
    st.session_state.history = []
if "draft_text" not in st.session_state:
    st.session_state.draft_text = ""
if "total_cost_usd" not in st.session_state:
    st.session_state.total_cost_usd = 0.0

# â˜…è¿½åŠ ï¼šç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥
if "student_img_cache" not in st.session_state:
    st.session_state.student_img_cache = []
if "ref_img_cache" not in st.session_state:
    st.session_state.ref_img_cache = []

# â˜…è¿½åŠ ï¼šç›´è¿‘ã®æ¡ç‚¹çµæœã‚’ä¿æŒã™ã‚‹å¤‰æ•°
if "latest_result" not in st.session_state:
    st.session_state.latest_result = None

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
DEFAULT_SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„é…æ…®ã®ã§ãã‚‹è‹±èªæ•™å¸«ã§ã™ã€‚
æç¤ºã•ã‚ŒãŸã€Œç”Ÿå¾’ã®ç­”æ¡ˆã€ã‚’ã€ŒåŸºæº–è³‡æ–™ã€ã«åŸºã¥ã„ã¦æ·»å‰Šãƒ»æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚

ã€æœ€é‡è¦ï¼šæ·»å‰Šã®å¿ƒæ§‹ãˆã€‘
* ã‚³ãƒ¡ãƒ³ãƒˆã¯è¨€ã„æ–¹ã®ãã¤ã„æ”»æ’ƒçš„ãªã‚‚ã®ã«ã¯æ±ºã—ã¦ã›ãšã«ã€ç”Ÿå¾’ãŒã‚„ã‚‹æ°—ã‚’å‡ºã›ãŸã‚Šæ£˜ã®ãªã„ã‚ˆã†ãªã‚³ãƒ¡ãƒ³ãƒˆã«ã—ã¦ãã ã•ã„ã€‚
* æ·»å‰Šã‚„æ¡ç‚¹ã‚’ã—ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ãŸç­”æ¡ˆã¯ç”Ÿå¾’ã®æ‰‹å…ƒã«è¿”ã™ã¨ã„ã†ã“ã¨ã‚’å¿µé ­ã«ç½®ã„ã¦ãã ã•ã„ã€‚

ã€å…·ä½“çš„ãªæ·»å‰ŠæŒ‡ç¤ºã€‘
1. **æ·»å‰Šã‚¹ã‚¿ã‚¤ãƒ«**:
   - ç”»åƒã«ç›´æ¥æ›¸ãè¾¼ã‚ãªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆä¸Šã§ã€Œä¸‹ç·šéƒ¨(1)ã€œã€ã®ã‚ˆã†ã«è©²å½“ç®‡æ‰€ã‚’å¼•ç”¨ã—ã€ç•ªå·ã‚’æŒ¯ã£ã¦æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
   - å„æŒ‡æ‘˜ã®ä¸‹ã«ã€å¯¾å¿œã™ã‚‹ä¿®æ­£ãƒ»è§£èª¬ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

2. **å„ãƒŸã‚¹ã®æŒ‡æ‘˜ã«ã¤ã„ã¦**:
   - ãªãœãã®éƒ¨åˆ†ãŒèª¤ã‚Šãªã®ã‹ï¼ˆç†ç”±ï¼‰
   - ã©ã®ã‚ˆã†ã«è¨‚æ­£ã™ã‚Œã°ã‚ˆã„ã®ã‹ï¼ˆæ”¹å–„æ¡ˆï¼‰
   - ãªãœãã†è¨‚æ­£ã™ã‚‹ã®ã‹ï¼ˆæ–‡æ³•çš„ãƒ»æ–‡è„ˆçš„ç†ç”±ï¼‰
   ä¸Šè¨˜ã‚’ä¸å¯§ã«è¿°ã¹ã¦ãã ã•ã„ã€‚

3. **å„å•é¡Œã”ã¨ã®ã‚³ãƒ¡ãƒ³ãƒˆ**:
   - é–“é•ã„ã®æŒ‡æ‘˜ã ã‘ã§ãªãã€ã§ãã¦ã„ã‚‹ç‚¹ï¼ˆè‰¯ã„ç‚¹ï¼‰ã‚‚å¿…ãšè¦‹ã¤ã‘ã¦ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚

4. **å…¨ä½“ã®ç·è©•**:
   - æœ€å¾Œã«ã€å¤§å•ã‚’é€šã—ãŸç·è©•ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
   - å…¨ä½“ã‚’é€šã—ã¦è‰¯ã‹ã£ãŸç‚¹ãƒ»æ”¹å–„ç‚¹ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚
   - ä»Šå¾Œã®å­¦ç¿’æŒ‡é‡ã¨ãªã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯Markdownå½¢å¼ã§è¦‹ã‚„ã™ãæ•´å½¢ã—ã¦ãã ã•ã„ã€‚
"""

# ==========================================
# é–¢æ•°
# ==========================================
def process_uploaded_file(uploaded_file):
    images = []
    if uploaded_file is None:
        return images
    try:
        uploaded_file.seek(0)
        if uploaded_file.type == "application/pdf":
            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            for page in doc:
                zoom = 3.0
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                images.append(img)
        else:
            img = Image.open(uploaded_file)
            images.append(img)
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    return images

def pil_to_base64(img):
    buffered = io.BytesIO()
    img.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def call_ai_hybrid(prompt_text, text_input, images, gemini_key, openai_key):
    # 1. Gemini
    try:
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        request_content = [prompt_text]
        if text_input:
            request_content.append(f"\n\nã€ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘\n{text_input}")
        request_content.extend(images)

        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        response = model.generate_content(request_content, safety_settings=safety_settings)
        if response.text:
            return response.text, "Gemini (Free)"
    except Exception as e:
        error_msg = str(e)
        if "429" in error_msg or "Quota" in error_msg or "limit" in error_msg.lower():
            st.warning("âš ï¸ Geminiåˆ¶é™ç™ºç”Ÿã€‚OpenAI (gpt-4o-mini) ã¸åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
        else:
            st.warning(f"âš ï¸ Geminiã‚¨ãƒ©ãƒ¼({error_msg})ã€‚OpenAIã¸åˆ‡ã‚Šæ›¿ãˆã¾ã™...")

    # 2. OpenAI Fallback
    if not openai_key:
        return "ã‚¨ãƒ©ãƒ¼: OpenAI APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—èµ·å‹•ä¸å¯ã€‚", "Error"

    try:
        client = openai.OpenAI(api_key=openai_key)
        messages = [{"role": "system", "content": prompt_text}]
        user_content = []
        if text_input:
            user_content.append({"type": "text", "text": f"ã€ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘\n{text_input}"})
        else:
             user_content.append({"type": "text", "text": "ä»¥ä¸‹ã®ç”»åƒã‚’å‡¦ç†ã—ã¦ãã ã•ã„ã€‚"})

        for img in images:
            b64_str = pil_to_base64(img)
            user_content.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{b64_str}", "detail": "high"}
            })
            
        messages.append({"role": "user", "content": user_content})

        response = client.chat.completions.create(
            model=OPENAI_MODEL_NAME, messages=messages, max_tokens=4000
        )
        result_text = response.choices[0].message.content
        
        usage = response.usage
        cost = (usage.prompt_tokens / 1_000_000 * COST_INPUT_PER_1M) + (usage.completion_tokens / 1_000_000 * COST_OUTPUT_PER_1M)
        st.session_state.total_cost_usd += cost
        return result_text, f"OpenAI ({OPENAI_MODEL_NAME})"

    except Exception as e:
        return f"OpenAIã¸ã®åˆ‡ã‚Šæ›¿ãˆã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {e}", "Error"

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
def main():
    st.set_page_config(page_title="æ·»å‰Šãã‚“v14", page_icon="ğŸ’®", layout="wide")
    st.title("ğŸ’® æ·»å‰Šãã‚“ v14 (çµæœè¡¨ç¤ºä¿®æ­£ç‰ˆ)")

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
    with st.sidebar:
        st.header("ğŸ”‘ APIè¨­å®š")
        try:
            default_gemini = st.secrets.get("GEMINI_API_KEY", GEMINI_API_KEY_DEFAULT)
            default_openai = st.secrets.get("OPENAI_API_KEY", "")
        except (FileNotFoundError, Exception):
            default_gemini = GEMINI_API_KEY_DEFAULT
            default_openai = ""
        
        gemini_key = st.text_input("Gemini API Key", value=default_gemini, type="password")
        openai_key = st.text_input("OpenAI API Key (äºˆå‚™)", value=default_openai, type="password")
        
        st.divider()
        st.header("ğŸ“Š OpenAI ã‚³ã‚¹ãƒˆ")
        cost_usd = st.session_state.total_cost_usd
        col_c1, col_c2 = st.columns(2)
        col_c1.metric("USD", f"${cost_usd:.4f}")
        col_c2.metric("JPY", f"Â¥{cost_usd * USD_JPY_RATE:.2f}")
        
        st.divider()
        mode = st.radio("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["å³å¯†æ¡ç‚¹ï¼ˆåŸºæº–è³‡æ–™ã‚ã‚Šï¼‰", "ä¸€èˆ¬æ·»å‰Š", "ã‚·ãƒ³ãƒ—ãƒ«æ–‡å­—èµ·ã“ã—ï¼ˆOCRã®ã¿ï¼‰"])
        
        if st.button("å…¨å±¥æ­´ãƒ»ä½œæ¥­ã‚¯ãƒªã‚¢"):
            st.session_state.history = []
            st.session_state.draft_text = ""
            st.session_state.student_img_cache = [] 
            st.session_state.ref_img_cache = []
            st.session_state.latest_result = None # ã“ã“ã‚‚ã‚¯ãƒªã‚¢
            st.session_state.total_cost_usd = 0.0
            st.rerun()

    if not gemini_key or gemini_key == "AIza...":
        st.warning("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›† ---
    with st.expander("ğŸ› ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†", expanded=False):
        custom_prompt = st.text_area("æŒ‡ç¤ºå†…å®¹", value=DEFAULT_SYSTEM_PROMPT, height=200)

    # --- ã‚¿ãƒ– ---
    tab_main, tab_history = st.tabs(["ğŸ“ æ¡ç‚¹ä½œæ¥­", "ğŸ•’ æ¡ç‚¹å±¥æ­´"])

    # ==========================================
    # ã‚¿ãƒ–1: ä½œæ¥­ã‚¨ãƒªã‚¢ (çŠ¶æ…‹é·ç§»ãƒ­ã‚¸ãƒƒã‚¯)
    # ==========================================
    with tab_main:
        
        # ----------------------------------------------
        # Phase 3: çµæœè¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ (æ·»å‰Šå®Œäº†å¾Œ)
        # ----------------------------------------------
        if st.session_state.latest_result:
            st.success("ğŸ‰ æ·»å‰ŠãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # çµæœè¡¨ç¤º
            st.markdown("---")
            st.markdown(st.session_state.latest_result)
            st.markdown("---")
            
            # ã€Œæ¬¡ã®ç”Ÿå¾’ã¸ã€ãƒœã‚¿ãƒ³
            if st.button("â¡ï¸ æ¬¡ã®ç”Ÿå¾’ã¸ (å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢)", type="primary", use_container_width=True):
                # çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦åˆæœŸç”»é¢ã¸
                st.session_state.draft_text = ""
                st.session_state.student_img_cache = []
                st.session_state.ref_img_cache = []
                st.session_state.latest_result = None
                st.rerun()

        # ----------------------------------------------
        # Phase 1: åˆæœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»é¢
        # ----------------------------------------------
        elif not st.session_state.draft_text:
            col1, col2 = st.columns(2)
            
            # åŸºæº–è³‡æ–™
            with col1:
                st.subheader("1. åŸºæº–è³‡æ–™")
                ref_files = st.file_uploader("åŸºæº–", type=["jpg", "png", "pdf"], key="ref", accept_multiple_files=True)
                if ref_files:
                    with st.expander("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                        for f in ref_files:
                            for img in process_uploaded_file(f):
                                st.image(img, use_container_width=True)

            # ç”Ÿå¾’ç­”æ¡ˆ
            with col2:
                st.subheader("2. ç”Ÿå¾’ã®ç­”æ¡ˆ")
                student_files = st.file_uploader("ç­”æ¡ˆ", type=["jpg", "png", "pdf"], key="student", accept_multiple_files=True)
                if student_files:
                    with st.expander("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
                        for f in student_files:
                            for img in process_uploaded_file(f):
                                st.image(img, use_container_width=True)

            st.divider()

            if student_files:
                st.subheader("Step 1: èª­ã¿å–ã‚Šé–‹å§‹")
                if st.button("â‘  èª­ã¿å–ã‚Šã‚’é–‹å§‹ (OCR)", type="primary", use_container_width=True):
                    with st.spinner("ç”»åƒã‚’ä¿å­˜ã—ã¦èª­ã¿å–ã£ã¦ã„ã¾ã™..."):
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
                        st.session_state.student_img_cache = []
                        st.session_state.ref_img_cache = []
                        
                        for f in student_files:
                            st.session_state.student_img_cache.extend(process_uploaded_file(f))
                        
                        if ref_files:
                            for f in ref_files:
                                st.session_state.ref_img_cache.extend(process_uploaded_file(f))

                        # OCRå®Ÿè¡Œ
                        ocr_prompt = "ç”»åƒã®è‹±æ–‡ã‚’ã€ã‚¹ãƒšãƒ«ãƒŸã‚¹ã‚’å«ã‚ã¦å¿ å®Ÿã«ãã®ã¾ã¾ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦ãã ã•ã„ã€‚è§£èª¬ä¸è¦ã€‚"
                        text_res, model_used = call_ai_hybrid(
                            prompt_text=ocr_prompt,
                            text_input="",
                            images=st.session_state.student_img_cache,
                            gemini_key=gemini_key,
                            openai_key=openai_key
                        )
                        
                        st.session_state.draft_text = text_res
                        st.rerun()

        # ----------------------------------------------
        # Phase 2: ç¢ºèªãƒ»ä¿®æ­£ç”»é¢
        # ----------------------------------------------
        else:
            st.info("âœ… èª­ã¿å–ã‚Šå®Œäº†ã€‚èª¤ã‚ŠãŒãªã„ã‹ç¢ºèªãƒ»ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
            
            current_student_images = st.session_state.student_img_cache
            current_ref_images = st.session_state.ref_img_cache

            edit_col, img_col = st.columns([1, 1])
            with edit_col:
                st.subheader("âœï¸ ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†")
                edited_text = st.text_area("ç­”æ¡ˆãƒ†ã‚­ã‚¹ãƒˆ", value=st.session_state.draft_text, height=600)
                
                # æˆ»ã‚‹ãƒœã‚¿ãƒ³
                if st.button("â†©ï¸ æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™"):
                    st.session_state.draft_text = ""
                    st.session_state.student_img_cache = []
                    st.session_state.ref_img_cache = []
                    st.rerun()

            with img_col:
                st.subheader("ğŸ” å…ƒç”»åƒ")
                for i, img in enumerate(current_student_images):
                    st.image(img, caption=f"Img {i+1}", use_container_width=True)

            st.divider()
            st.subheader("Step 2: æ·»å‰Šå®Ÿè¡Œ")
            
            if st.button("â‘¡ æ·»å‰Šã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
                if mode == "ã‚·ãƒ³ãƒ—ãƒ«æ–‡å­—èµ·ã“ã—ï¼ˆOCRã®ã¿ï¼‰":
                    st.success("å®Œäº†ï¼")
                    st.text_area("çµæœ", value=edited_text)
                    # æ–‡å­—èµ·ã“ã—ã®ã¿ã®å ´åˆã¯ã“ã“ã§Resultã«å…¥ã‚Œã¦è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã¸
                    st.session_state.latest_result = f"```text\n{edited_text}\n```"
                    st.rerun()
                else:
                    with st.spinner("AIãŒæ·»å‰Šä¸­..."):
                        final_prompt = custom_prompt
                        if mode == "ä¸€èˆ¬æ·»å‰Š":
                            final_prompt = "è‹±èªè¬›å¸«ã¨ã—ã¦ã€ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚"
                        
                        images_to_send = current_ref_images if (mode == "å³å¯†æ¡ç‚¹ï¼ˆåŸºæº–è³‡æ–™ã‚ã‚Šï¼‰" and current_ref_images) else current_student_images

                        text_res, model_used = call_ai_hybrid(
                            prompt_text=final_prompt,
                            text_input=edited_text,
                            images=images_to_send,
                            gemini_key=gemini_key,
                            openai_key=openai_key
                        )

                        timestamp = datetime.datetime.now().strftime("%Y/%m/%d %H:%M:%S")
                        full_result = f"### ğŸ“ ä¿®æ­£æ¸ˆã¿ç­”æ¡ˆ\n```text\n{edited_text}\n```\n\n### ğŸ¤– AI ({model_used})\n{text_res}"
                        
                        # å±¥æ­´ä¿å­˜
                        st.session_state.history.insert(0, {
                            "time": timestamp,
                            "title": f"çµæœ ({model_used})",
                            "mode": mode,
                            "result": full_result
                        })
                        
                        # â˜…ã“ã“ã‚’å¤‰æ›´: ã™ãæ¶ˆã•ãšã«ã€çµæœè¡¨ç¤ºå¤‰æ•°ã«å…¥ã‚Œã‚‹
                        st.session_state.latest_result = full_result
                        st.rerun()

    # ==========================================
    # ã‚¿ãƒ–2: å±¥æ­´
    # ==========================================
    with tab_history:
        st.subheader("ğŸ•’ æ¡ç‚¹å±¥æ­´")
        if not st.session_state.history:
            st.info("å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            for record in st.session_state.history:
                with st.expander(f"[{record['time']}] {record['title']}"):
                    st.markdown(record['result'])

if __name__ == "__main__":
    main()